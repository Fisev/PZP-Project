{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Fisev/PZP-Project/blob/Petlu/Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#get files\n",
        "!wget https://raw.githubusercontent.com/Fisev/PZP-Project/refs/heads/main/data.txt -O data.txt\n",
        "!wget https://raw.githubusercontent.com/Fisev/PZP-Project/refs/heads/main/stop_words.txt -O stop_words.txt\n",
        "\n",
        "pattern = re.compile(r'[^a-zA-Z]')\n",
        "min_length = 4\n",
        "max_length = 8"
      ],
      "metadata": {
        "id": "QALRtH9W8b_M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    # Read lullaby text\n",
        "    with open(\"data.txt\", \"r\") as file:\n",
        "        f_lullaby = file.read().lower()  # Read the entire text as a string\n",
        "\n",
        "    # Read stop words and create a set for quick lookups\n",
        "    with open(\"stop_words.txt\", \"r\") as file:\n",
        "        f_stopW = set(file.read().lower().split())  # Use a set for faster membership checking\n",
        "\n",
        "    # Clean the text: remove punctuation\n",
        "    cleaned_text = pattern.sub(' ', f_lullaby)\n",
        "\n",
        "    # Split the cleaned text into words\n",
        "    words = cleaned_text.split()\n",
        "\n",
        "    # Create a Counter to track word occurrences directly while filtering\n",
        "    word_counts = Counter()\n",
        "    filtered_words = []  # List to store filtered words\n",
        "\n",
        "    # Filter and count words in a single loop\n",
        "    for word in words:\n",
        "        cleaned_word = pattern.sub('', word)  # Clean each word\n",
        "        if min_length <= len(cleaned_word) <= max_length and cleaned_word not in f_stopW:\n",
        "            word_counts[cleaned_word] += 1\n",
        "            filtered_words.append(cleaned_word)  # Store the filtered word\n",
        "\n",
        "    # Get the most and least frequent words\n",
        "    most_frequent_word, most_frequent_count = word_counts.most_common(1)[0] if word_counts else (None, 0)\n",
        "    least_frequent_word, least_frequent_count = min(word_counts.items(), key=lambda x: x[1], default=(None, 0))\n",
        "\n",
        "    # Total number of words after filtering\n",
        "    total_filtered_words = sum(word_counts.values())\n",
        "\n",
        "    # Print the results\n",
        "    print(f\"Stop words: {list(f_stopW)}\")  # Optionally print stop words for reference\n",
        "    print(f\"Filtered words: {filtered_words}\")  # Print the filtered words\n",
        "    print(f\"Most frequent word: '{most_frequent_word}' with {most_frequent_count} occurrences\")\n",
        "    print(f\"Least frequent word: '{least_frequent_word}' with {least_frequent_count} occurrences\")\n",
        "    print(f\"Total number of filtered words: {total_filtered_words}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Reading failed: {e}\")"
      ],
      "metadata": {
        "id": "td0RaBsBCQAO",
        "outputId": "570167cd-a650-4674-9822-266a746b6950",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop words: ['ferrule', 'summer-house', 'electronic', 'warranty', 'barbarians', 'gutenberg', 'version', 'odorous', 'queequeg', 'thee']\n",
            "Filtered words: []\n",
            "Most frequent word: 'the' with 14620 occurrences\n",
            "Least frequent word: 'january' with 1 occurrences\n",
            "Total number of filtered words: 221558\n"
          ]
        }
      ]
    }
  ]
}